x -> 0
x <- 0
y <- 5
x*x + y *y
# The linkedin and facebook vectors have already been created for you
linkedin <- c(16, 9, 13, 5, 2, 17, 14)
# Define the interpret_all() function
# views: vector with data to interpret
# return_sum: return total number of views on popular days?
interpret_all <- function(views, return_sum = TRUE) {
count <- 0
for (v in views) {
x = interpret(v)
count <- count + x
}
if (return_sum == TRUE) {
return(count)
} else {
NULL
}
}
debug(interpret_all)
debug(interpret)
# Call the interpret_all() function on both linkedin and facebook
interpret_all(linkedin)
install.packages("devtools")
file.exists("~/.ssh/id_rsa.pub")
ex <- read.csv()
ex <- read.csv("F:\\springboard\\wrangling problem\\refine_original")
ex <- read.csv("F:\springboard\wrangling problem\refine_original")
ex <- read.csv(file = "F:\\springboard\\wrangling problem\\refine_original")
ex <- read.csv(file = "F:\\springboard\\wrangling problem\\refine_original.csv")
ex
refine_df <- data.frame(ex)
refine_df
head(refine_df)
refine_df(company)
refine_df[1]
setwd("F:/Git/capstone-project")
install.packages("xgboost")
install.packages("dtree")
# Load all the packages used in the analysis
library("tidyverse")
library("lubridate")
library("caTools")
library("xgboost")
# Read the files
V_Fact_VoyPNL_File <- "F:\\Git\\capstone project\\dataSets\\V_Fact_VoyPNL.csv"
test_File <- "F:\\Git\\capstone project\\dataSets\\test.csv"
V_Dim_CargoAndGrade_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_CargoAndGrade.csv"
V_Dim_Vessel_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_Vessel.csv"
V_Dim_Voyage_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_Voyage.csv"
# Store the data into dataframe and check for blanks and NA
V_Fact_VoyPNL <- read.csv(V_Fact_VoyPNL_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
test <- read.csv(test_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
V_Dim_CargoAndGrade <- read.csv(V_Dim_CargoAndGrade_File, na.strings=c("","NA"),
stringsAsFactors = FALSE)
V_Dim_Vessel <- read.csv(V_Dim_Vessel_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
V_Dim_Voyage <- read.csv(V_Dim_Voyage_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
# removing records with Fkey_Dim_Voyage_Id = -1
V_Fact_VoyPNL <- filter(V_Fact_VoyPNL, V_Fact_VoyPNL$Fkey_Dim_Voyage_Id != "-1")
V_Dim_Vessel <- filter(V_Dim_Vessel, V_Dim_Vessel$Dim_Vessel_Id != "-1")
# get the voyage completion date into proper format.
V_Fact_VoyPNL$Month <- lubridate::month(ymd(V_Fact_VoyPNL$Fkey_DimTime_CompletedGMT),label=TRUE)
V_Fact_VoyPNL$Year <- lubridate::year(ymd(V_Fact_VoyPNL$Fkey_DimTime_CompletedGMT))
# considering data with only data_type = "A" and BatchId
v_mod<- V_Fact_VoyPNL[V_Fact_VoyPNL$data_type=='A' &
V_Fact_VoyPNL$BatchId==max(V_Fact_VoyPNL$BatchId),]
#combine similar vessel types into one category.
v_mod$vsl_type <- sub(pattern = "^HAN.*", replacement = "HANDYMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^MID.*", replacement = "MIDRANGE", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^PAN.*", replacement = "PANAMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^AFR.*", replacement = "AFRAMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^LR1.*", replacement = "LR1", x = v_mod$vsl_type)
#Restrict the number of ports by matching them with areas
v_mod$lastDiscPort <- test$Region[match(v_mod$lastDiscPort,test$PortName)]
v_mod$firstLoadPort <- test$Region[match(v_mod$firstLoadPort,test$PortName)]
#Restrict the cargo types by matching them with Cargo text from the cargo table
v_mod$Cargo <- V_Dim_CargoAndGrade$CargoGrade_txt[match(v_mod$cargoShort,
V_Dim_CargoAndGrade$Cargo_ShortName)]
# Join dwt column from V_Dim_Vessel table to the dataset
v_mod <- v_mod %>% left_join(V_Dim_Vessel[,c("Dim_Vessel_Id","dwt")],
by=c("Fkey_Dim_Vessel_Id"="Dim_Vessel_Id"))
# Join estimate earnings and estimate voyage days columns from V_Dim_Voyage to the datset
v_mod <- left_join(v_mod,V_Dim_Voyage[,c("Dim_Voyage_Id","TCEquiv_Estimate_LatestDaySnapshot",
"TotalVoyageDays_Estimate_LatestDaySnapshot")],
by = c("Fkey_Dim_Voyage_Id" = "Dim_Voyage_Id"))
# Change the column names for easy understanding
v_mod$TotalVoyageDays_Est <- v_mod$TotalVoyageDays_Estimate_LatestDaySnapshot
v_mod$TCEquiv_Est <- v_mod$TCEquiv_Estimate_LatestDaySnapshot
# Calculate daily earnings for each voyage
v_mod <- filter(v_mod, (v_mod$TCEquiv_Est != 0) || (v_mod$TotalVoyageDays_Est != 0))
v_mod <- filter(v_mod,  v_mod$TotalVoyageDays_Est >= 1)
v_mod$dailyrate_Est <- v_mod$TCEquiv_Est / v_mod$TotalVoyageDays_Est
# Calculate the difference between estimated earnings and actual earnings
v_mod$diff_TCEquiv <- v_mod$TotalVoyageDays_Est - v_mod$tcEquv_Act
#one-hot encoding categorial features
ohe_feats <- c("vsl_type","Cargo","Month","lastDiscPort")
?dummyVars
vslt_factor <- factor(v_mod$vsl_type)
dummies <- model.matrix(~vslt_factor)
head(dummies)
dim(dummies)
head(v_mod$vsl_type)
colnames(v_mod)
v_mod_trial <- v_mod
?cbind
dummies <- as.data.frame(model.matrix(~vslt_factor))
head(dummies)
dim(dummies)
head(v_mod$vsl_type)
v_mod_trial <- cbind(dummies[-1],v_mod_trial)
colnames(v_mod_trial)
v_mod_trial <- v_mod
v_mod_trial <- cbind(v_mod_trial,dummies[-1])
colnames(v_mod_trial)
install.packages("caret")
library("caret")
dummies_new <- as.data.frame(dummyVars(~vsl_type + Cargo + Month + lastDiscPort, data=v_mod))
dummies_new <- dummyVars(~vsl_type + Cargo + Month + lastDiscPort, data=v_mod)
head(dummies_new)
dummies_new
View(dummies_new)
# Load all the packages used in the analysis
library("tidyverse")
library("lubridate")
library("caTools")
library("xgboost")
library("caret")
# Read the files
V_Fact_VoyPNL_File <- "F:\\Git\\capstone project\\dataSets\\V_Fact_VoyPNL.csv"
test_File <- "F:\\Git\\capstone project\\dataSets\\test.csv"
V_Dim_CargoAndGrade_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_CargoAndGrade.csv"
V_Dim_Vessel_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_Vessel.csv"
V_Dim_Voyage_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_Voyage.csv"
# Store the data into dataframe and check for blanks and NA
V_Fact_VoyPNL <- read.csv(V_Fact_VoyPNL_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
test <- read.csv(test_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
V_Dim_CargoAndGrade <- read.csv(V_Dim_CargoAndGrade_File, na.strings=c("","NA"),
stringsAsFactors = FALSE)
V_Dim_Vessel <- read.csv(V_Dim_Vessel_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
V_Dim_Voyage <- read.csv(V_Dim_Voyage_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
# removing records with Fkey_Dim_Voyage_Id = -1
V_Fact_VoyPNL <- filter(V_Fact_VoyPNL, V_Fact_VoyPNL$Fkey_Dim_Voyage_Id != "-1")
V_Dim_Vessel <- filter(V_Dim_Vessel, V_Dim_Vessel$Dim_Vessel_Id != "-1")
# get the voyage completion date into proper format.
V_Fact_VoyPNL$Month <- lubridate::month(ymd(V_Fact_VoyPNL$Fkey_DimTime_CompletedGMT),label=TRUE)
V_Fact_VoyPNL$Year <- lubridate::year(ymd(V_Fact_VoyPNL$Fkey_DimTime_CompletedGMT))
# considering data with only data_type = "A" and BatchId
v_mod<- V_Fact_VoyPNL[V_Fact_VoyPNL$data_type=='A' &
V_Fact_VoyPNL$BatchId==max(V_Fact_VoyPNL$BatchId),]
#combine similar vessel types into one category.
v_mod$vsl_type <- sub(pattern = "^HAN.*", replacement = "HANDYMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^MID.*", replacement = "MIDRANGE", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^PAN.*", replacement = "PANAMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^AFR.*", replacement = "AFRAMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^LR1.*", replacement = "LR1", x = v_mod$vsl_type)
#Restrict the number of ports by matching them with areas
v_mod$lastDiscPort <- test$Region[match(v_mod$lastDiscPort,test$PortName)]
v_mod$firstLoadPort <- test$Region[match(v_mod$firstLoadPort,test$PortName)]
#Restrict the cargo types by matching them with Cargo text from the cargo table
v_mod$Cargo <- V_Dim_CargoAndGrade$CargoGrade_txt[match(v_mod$cargoShort,
V_Dim_CargoAndGrade$Cargo_ShortName)]
# Join dwt column from V_Dim_Vessel table to the dataset
v_mod <- v_mod %>% left_join(V_Dim_Vessel[,c("Dim_Vessel_Id","dwt")],
by=c("Fkey_Dim_Vessel_Id"="Dim_Vessel_Id"))
# Join estimate earnings and estimate voyage days columns from V_Dim_Voyage to the datset
v_mod <- left_join(v_mod,V_Dim_Voyage[,c("Dim_Voyage_Id","TCEquiv_Estimate_LatestDaySnapshot",
"TotalVoyageDays_Estimate_LatestDaySnapshot")],
by = c("Fkey_Dim_Voyage_Id" = "Dim_Voyage_Id"))
# Change the column names for easy understanding
v_mod$TotalVoyageDays_Est <- v_mod$TotalVoyageDays_Estimate_LatestDaySnapshot
v_mod$TCEquiv_Est <- v_mod$TCEquiv_Estimate_LatestDaySnapshot
# Calculate daily earnings for each voyage
v_mod <- filter(v_mod, (v_mod$TCEquiv_Est != 0) || (v_mod$TotalVoyageDays_Est != 0))
v_mod <- filter(v_mod,  v_mod$TotalVoyageDays_Est >= 1)
v_mod$dailyrate_Est <- v_mod$TCEquiv_Est / v_mod$TotalVoyageDays_Est
# Calculate the difference between estimated earnings and actual earnings
v_mod$diff_TCEquiv <- v_mod$TotalVoyageDays_Est - v_mod$tcEquv_Act
?xgboost
install.packages("tree")
?tree
library("tree")
data <- data.frame(
stringsAsFactors = FALSE,
package = c("processx", "backports", "assertthat", "Matrix",
"magrittr", "rprojroot", "clisymbols", "prettyunits", "withr",
"desc", "igraph", "R6", "crayon", "debugme", "digest", "irlba",
"rcmdcheck", "callr", "pkgconfig", "lattice"),
dependencies = I(list(
c("assertthat", "crayon", "debugme", "R6"), character(0),
character(0), "lattice", character(0), "backports", character(0),
c("magrittr", "assertthat"), character(0),
c("assertthat", "R6", "crayon", "rprojroot"),
c("irlba", "magrittr", "Matrix", "pkgconfig"), character(0),
character(0), "crayon", character(0), "Matrix",
c("callr", "clisymbols", "crayon", "desc", "digest", "prettyunits",
"R6", "rprojroot", "withr"),
c("processx", "R6"), character(0), character(0)
))
)
head(data)
tree(data)
tree(data)
tree(data, root = "rcmdcheck")
version
tree(data)
install.packages("tree")
head(data)
tree(data)
library("tree")
library("tree")
