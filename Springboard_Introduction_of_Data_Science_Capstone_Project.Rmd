---
output:
  html_document: default
  pdf_document: default
---
# Springboard Introduction to Data Science Capstone Project 
### By Rucha Joshi

## **Maritime Data Intelligence System - Predicting the revenue of Ship Chartering Business**

### **Introduction:**

Shipping has been key in facilitating trade and globalization. It is one of the largest industry in the world. This sector handles roughly 60% of the value and 75% of the tonnage of world trade according to Lloyd's MIU.  
Chartering is an activity in the shipping industry whereby a shipowner hires out the use of his vessel to a charterer. The contract between the parties is called a "charter party".  
A voyage charter is the hiring of a vessel and crew for a voyage between a load port and a discharge port. The charterer pays the vessel owner on a per-ton or lump-sum basis. The owner pays the port costs (excluding stevedoring), fuel costs and crew costs. The payment for the use of the vessel is known as freight. In some cases a charterer may own cargo and employ a shipbroker to find a ship to deliver the cargo for a certain price, called freight rate. Freight rates may be on a per-ton basis over a certain route (e.g. for iron ore between Brazil and China), in World scale points (in case of oil tankers) or alternatively may be expressed in terms of a total sum - normally in U.S. dollars - per day for the agreed duration of the charter.A charterer may also be a party without a cargo who takes a vessel on charter for a specified period from the owner and then trades the ship to carry cargoes at a profit above the hire rate, or even makes a profit in a rising market by re-letting the ship out to other charterers.  
Depending on the type of ship and the type of charter, normally a standard contract form called a charter party is used to record the exact rate, duration and terms agreed between the shipowner and the charterer.  
Time Charter Equivalent is a standard shipping industry performance measure used primarily to compare period-to-period changes in a shipping company's performance despite changes in the mix of charter types.  

The objective of this project is to maximize the revenues in ship chartering/contracting business through efficient operational planning and optimization of resources by analyzing their previous years data.  



### **Problem Statement:**   

Shipping industry is very competitive, in addition to competing with each other, they must fight with all four modes of freight transportation: air, rail, water and road. Recently these conscious shippers are getting more aware of all the costs by analyzing their history data to make more precise decisions.  
Prediction of the revenue on the particular charter by creating a machine learning model based on the previous year's available data will help the shipper to choose best trades to get the maximum profit.  
Our goal in this analysis is to help shipowners to choose the charter wisely to maximize their profits by identifying the cost affecting factors on the voyage.  
We will build the model that can explain which factors have predictive power.  




### **Data Set:** 

The dataset was received from the ship chartering company.    
The dataset includes about 185,000 observations which has voyages from 2009 across the world. The other datasets are Port details, Vessel details and Voyage details.     

The data includes following important fields -   
1.	Voyage Id - Id assigned to each voyage  
2.	Vessel Id - Id assigned to each vessel  
3.	Commencing Date - Start date for the voyage  
4.	Completing Date - End date for the voyage  
5.	Vessel types - There are total 12 different types of vessels.  
6.	Vessel description - Is vessel a Tanker or a Bulk  
7.	Cargo types- There are 20 unique values of cargo types.  
8.	First load port - This is the port where first vessel got loaded.  
9.	Last discharge port - This is the last discharge port for the voyage. There can be multiple         discharge ports for single voyage.  
10.	Cargo type - It gives information about what type of cargo vessel is carrying.  
11.	Cargo lift - It tells us how much cargo the vessel is carrying.  
12.	Dwt - Deadweight tonnage of the ship.  
13.	Estimated earnings and Actual Earnings   
14.	Trade Area - The area where the voyage is travelling.  
15.	Estimated voyage days and Actual voyage days  
16.	Ballast days - when vessel is empty  
17.	Laden days - when vessel is loaded  
18.	Base Currency - Currency of earnings   
19.	Operators details  
20.	Laden and Ballast Speed - this is finalized at the charter party.  
21.	Vessel properties such as built year, owner etc.  

And there are few more fields for internal use of the shippers which are not relevant to our analysis.  




### **Data Limitations:**

Some of the observations has missing values as all this data has been manually entered in the system.   
The data contains cancelled voyages as well so we need separate that data as we don't have more details about those voyages we can not consider those cancellations reasons for our prediction.
Weather is one of the major factors in the earnings of these voyages. We have not received any weather data as fuel consumption depends on the weather and it is a major factor of daily expenses of a voyage.  
Any conclusions from this study should take into account that including these factors may have led to different results.  




### **Data Wrangling:**

The dataset was comprehensive with few missing values. It required some cleanup and reformatting. The steps taken are described below. For detailed review of the code, R markdown document explaining each step with code is included.  

Rows which were not needed for analysis were removed for example observations which had Id = -1 were removed from the dataset. In addition, column headings in the data set needed to be transformed from ambiguous names which gives clear description of each variable.  

The dataset imported into R was stored in the data frame where I checked for NA's and spaces and tried to remove factor levels. These transformations were helpful to conduct preliminary exploration and data visualization.   

Now data had lot of categorical variables like vessel type, cargo type; so, I tried to combine similar types into one category so that we can have limited categories to find the trends in the data.  

Similarly, first loading port, last discharge port and trade area were replaced with region names so that we can find which are the regions gives more earnings and which trade area has more earnings.   
In the ports data few observations had 0 longitude and 0 latitude, so we decided to remove these records.  

For a single voyage there are multiple records with different data types as A - actual, E - Estimate and P- positional. We decided to use actual data for our analysis as estimate and positional type had lot of missing values.  

If first loading port and/or last discharge port has blank value or actual earnings has zero value then those voyages got cancel due to some reason.  

After doing all this cleaning and reformatting the data is ready for preliminary exploration.  



### **Preliminary Exploration:**

The goal of preliminary exploration was to find independent variables that appear to have some predictive power. 


**I.**	First we tried to find the top earning vessels by plotting sum of the earnings per year for each vessel type.  

```{r, echo = FALSE,warning = FALSE,message = FALSE}
# Capstone Project - Maritime Data Intelligence System R code

## Data Wrangling

# Load all the packages used in the analysis
library("tidyverse")
library("lubridate")
library("caTools")

# Read the files
V_Fact_VoyPNL_File <- "F:\\Git\\capstone project\\dataSets\\V_Fact_VoyPNL.csv"
test_File <- "F:\\Git\\capstone project\\dataSets\\test.csv"
V_Dim_CargoAndGrade_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_CargoAndGrade.csv"
V_Dim_Vessel_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_Vessel.csv"
V_Dim_Voyage_File <- "F:\\Git\\capstone project\\dataSets\\V_Dim_Voyage.csv"

# Store the data into dataframe and check for blanks and NA
V_Fact_VoyPNL <- read.csv(V_Fact_VoyPNL_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
test <- read.csv(test_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
V_Dim_CargoAndGrade <- read.csv(V_Dim_CargoAndGrade_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
V_Dim_Vessel <- read.csv(V_Dim_Vessel_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
V_Dim_Voyage <- read.csv(V_Dim_Voyage_File, na.strings=c("","NA"), stringsAsFactors = FALSE)
```

```{r, eval=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
#Look at the structure of the dataset
glimpse(V_Fact_VoyPNL)
glimpse(test)
glimpse(V_Dim_CargoAndGrade)
glimpse(V_Dim_Vessel)
glimpse(V_Dim_Voyage)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# removing records with Fkey_Dim_Voyage_Id = -1
V_Fact_VoyPNL <- filter(V_Fact_VoyPNL, V_Fact_VoyPNL$Fkey_Dim_Voyage_Id != "-1")
V_Dim_Vessel <- filter(V_Dim_Vessel, V_Dim_Vessel$Dim_Vessel_Id != "-1")

# get the voyage completion date into proper format.
V_Fact_VoyPNL$Month <- lubridate::month(ymd(V_Fact_VoyPNL$Fkey_DimTime_CompletedGMT),label=TRUE)
V_Fact_VoyPNL$Year <- lubridate::year(ymd(V_Fact_VoyPNL$Fkey_DimTime_CompletedGMT))

# considering data with only data_type = "A" and BatchId 
v_mod<- V_Fact_VoyPNL[V_Fact_VoyPNL$data_type=='A' & V_Fact_VoyPNL$BatchId==max(V_Fact_VoyPNL$BatchId),]

#combine similar vessel types into one category.
v_mod$vsl_type <- sub(pattern = "^HAN.*", replacement = "HANDYMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^MID.*", replacement = "MIDRANGE", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^PAN.*", replacement = "PANAMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^AFR.*", replacement = "AFRAMAX", x = v_mod$vsl_type)
v_mod$vsl_type <- sub(pattern = "^LR1.*", replacement = "LR1", x = v_mod$vsl_type)

#Restrict the number of ports by matching them with areas
v_mod$lastDiscPort <- test$Region[match(v_mod$lastDiscPort,test$PortName)]
v_mod$firstLoadPort <- test$Region[match(v_mod$firstLoadPort,test$PortName)]

#Restrict the cargo types by matching them with Cargo text from the cargo table
v_mod$Cargo <- V_Dim_CargoAndGrade$CargoGrade_txt[match(v_mod$cargoShort,V_Dim_CargoAndGrade$Cargo_ShortName)]

# Join dwt column from V_Dim_Vessel table to the dataset
v_mod <- v_mod %>% left_join(V_Dim_Vessel[,c("Dim_Vessel_Id","dwt")], by=c("Fkey_Dim_Vessel_Id"="Dim_Vessel_Id"))

# Join estimate earnings and estimate voyage days columns from V_Dim_Voyage to the datset
v_mod <- left_join(v_mod,V_Dim_Voyage[,c("Dim_Voyage_Id","TCEquiv_Estimate_LatestDaySnapshot","TotalVoyageDays_Estimate_LatestDaySnapshot")],by = c("Fkey_Dim_Voyage_Id" = "Dim_Voyage_Id"))

# Calculate daily earnings for each voyage
v_mod <- filter(v_mod, (v_mod$TCEquiv_Estimate_LatestDaySnapshot != 0) || (v_mod$TotalVoyageDays_Estimate_LatestDaySnapshot != 0))
v_mod <- filter(v_mod,  v_mod$TotalVoyageDays_Estimate_LatestDaySnapshot >= 1)
v_mod$dailyrate_Est <- v_mod$TCEquiv_Estimate_LatestDaySnapshot / v_mod$TotalVoyageDays_Estimate_LatestDaySnapshot

# Calculate the difference between estimated earnings and actual earnings
v_mod$diff_TCEquiv <- v_mod$TotalVoyageDays_Estimate_LatestDaySnapshot - v_mod$tcEquv_Act
```

```{r, echo=FALSE, warning=FALSE, fig.height=20,fig.width=15}
# sum of earnings for each year for each vessel type
sumv2 <- aggregate(v_mod[,c("tcEquv_Act")],list(Year=v_mod$Year,vsl_type=v_mod$vsl_type), sum)

# plot average of each year for each type of vessel
sumv2yr <- sumv2[sumv2$Year <= 2019 & sumv2$Year >= 2010,]

ggplot(sumv2yr, aes(x=vsl_type,y=x)) +
  geom_bar(aes(fill = factor(vsl_type)),stat="identity")+
  facet_wrap(~Year, ncol = 2, nrow = 5) +
  theme(axis.text.x = element_text(angle=45,hjust = 1), plot.title = element_text(hjust = 0.5)) +     labs(title = "Sum of earnings vs Vessel type", x = "Vessel type", y = "Sum of earnings(USD)") +
  guides(fill=guide_legend(title = "Vessel Type"))  
```

It shows that every year Handymax Pool, Midrange Pool are doing good business. Chemical tanker is in business in only 2017. Cobra was in business just for 3 years from 2014, 2015, 2016.  
From the plots, out of the total earnings of all the vessel types for all the years, about 80% of the earnings are from Midrange Pool, Handymax Pool, Panamax Pool and Aframax  LR2 Pool.
Therefore, we can say that majority of business is done by these pool vessel type.   
In 2017 out of $28 million business $23 million business is done by Midrange Pool, Handymax Pool, Aframax LR2 pool.  

**III.**	The next plot is average of the earnings per year for all vessel types.  

```{r, echo=FALSE, warning=FALSE, fig.height=20,fig.width=15}
# Calculate average earnings for each year for each vessel type
avgv2 <- aggregate(v_mod[,c("tcEquv_Act")],list(Year=v_mod$Year,vsl_type=v_mod$vsl_type), mean)

# plot average of earnings from 2010 to 2019 for each vessel type
avgv2yr <- avgv2[avgv2$Year <= 2019 & avgv2$Year >= 2010,]

ggplot(avgv2yr, aes(x=vsl_type,y=x)) +
  geom_bar(aes(fill = factor(vsl_type)),stat="identity")+
  facet_wrap(~Year, ncol = 2, nrow = 5) +
  theme(axis.text.x = element_text(angle=45,hjust = 1), plot.title = element_text(hjust = 0.5)) +     labs(title = "Average earnings vs Vessel type", x = "Vessel type", y = "Average earnings(USD)") +
  guides(fill=guide_legend(title = "Vessel Type"))   
```

**IV.** Next plots give average earnings for each vessel type for all the years.

```{r, echo=FALSE, warning=FALSE}
#calculate average earnings for each vessel type for all years
avgv3 <- aggregate(v_mod[,c("tcEquv_Act")],list(vsl_type=v_mod$vsl_type), mean)

# plot average for each vessel type for all years
ggplot(avgv3, aes(x=vsl_type,y=x)) +
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=45,hjust = 1), plot.title = element_text(hjust = 0.5)) +     labs(title = "Average earnings vs Vessel type", x = "Vessel type", y = "Average earnings(USD)") 
```

Here it is showing Cobra has highest earnings but Cobra was used just for 3 years (2014,2015,2016). This plot is not so useful as some vessel types has data for 10 years and some are used for couple of years whereas some are recent in the business. It will not be fare to compare these results to find the best one.  

**V.**	I used box plot to plot monthly earning distribution to find out seasonality.

```{r, echo=FALSE, warning=FALSE}
ggplot(v_mod, aes(x=Month, y=tcEquv_Act)) +
    geom_boxplot()
```

Plot does not show much of seasonality.   

Another plot is Average earnings vs Month  

```{r, echo=FALSE, warning=FALSE}
#Calculate average monthly earnings for each month
avgv6 <- aggregate(v_mod[,c("tcEquv_Act")],list(Month=v_mod$Month), mean)

#plot average monthly earnings for each month
ggplot(avgv6, aes(x=sort(Month),y=x)) +
  geom_bar(stat="identity",position = "dodge")+
  theme(axis.text.x = element_text(angle=45,hjust = 1), plot.title = element_text(hjust = 0.5)) +     labs(title = "Average earnings vs Month", x = "Month", y = "Average earnings(USD)") 
```

This shows the whole year business is going on.

**VI.**	This plot has been plotted to find top trade areas from sum of earnings.  

```{r, echo=FALSE, warning=FALSE, fig.width=20}
#sum of earnings for top 50 trade area
sumv4 <- aggregate(v_mod[,c("tcEquv_Act")],list(trade_area=v_mod$tradeArea), sum)
sumv4 <- sumv4[order(-sumv4$x),]

sumv5 <- head(sumv4, n=50)

#plot sum for top 50 trade area
ggplot(sumv5, aes(x=reorder(trade_area,-x),y=x)) +
  geom_bar(stat="identity",position = "dodge") +
  theme(axis.text.x = element_text(angle=45,hjust = 1), plot.title = element_text(hjust = 0.5)) +     labs(title = "Sum of earnings vs Trade Area", x = "Trade Area", y = "Sum of earnings(USD)") 
```

This plot shows that major business is done in Transatlantic area.

**VII.**	This plot has been plotted to find top cargo types from sum of earnings.  

```{r, echo=FALSE, warning=FALSE}
#Sum of earnings for each Cargo type
sumv6 <- aggregate(v_mod[,c("tcEquv_Act")],list(cargo_type=v_mod$Cargo), sum)
sumv6 <- sumv6[order(-sumv6$x),]

#plot sum of earnings for each cargo type
ggplot(sumv6, aes(x=reorder(cargo_type,-x),y=x)) +
  geom_bar(stat="identity",position = "dodge")+
  theme(axis.text.x = element_text(angle=45,hjust = 1), plot.title = element_text(hjust = 0.5)) +     labs(title = "Sum of earnings vs Cargo type", x = "Cargo type", y = "Sum of earnings(USD)") 
```

First 10 cargo types are generating 75% of the business.  

Based on this analysis, earnings of these voyages are dependent on mainly below mentioned factors: - 
1.	Vessel type - there are different types of vessels; most profitable are MIDRANGE, HANDYMAX, AFRAMAX, PANAMAX
2.	Cargo type- there are mainly two categories of cargo - dry cargo (coal, iron etc.) and liquid cargo (crude oil, gasoline, vegetable oil etc.). Most profitable are FO, CPP, ULSD, Gasoline, Naphtha and Gas Oil etc.
3.	Dwt - this is the capacity of the vessel. 
4.	Actual Cargo lift - How much cargo the particular vessel is carrying affects the earnings.
5.	Month - The period of the year in which this voyage is happening also affects the total earnings.
6.	 Region - the region in which the voyage is starting, loading and discharging also affect its earnings. Most profitable region is Transatlantic area.
7.	Daily expense - It includes their daily fuel usage, port fees, jetty charges, food for crew etc. Their 60% of expense is on fuel.

We can say from all of the above plots that voyages with vessel types like MIDRANGE, HANDYMAX carrying FO, CPP, ULSD, Gasoline, Naphtha and Gas Oil etc. in the transatlantic area have more earnings making the business profitable.



### **Machine Learning:**

In this section we built model that predict the earnings of the voyage. We built a linear regression model.  

#### **Linear Regression:**

Linear regression is used to predict the value of an outcome variable Y based on one or more input predictor variables X. The aim is to establish a linear relationship (a mathematical formula) between the predictor variable(s) and the response variable, so that, we can use this formula to estimate the value of the response Y, when only the predictors (Xs) values are known.  

We first split the data into training dataset and testing dataset. The training dataset was used to build the model to find predictive relationship. The testing data set was used to assess the performance of the model.  

The training dataset used 70% of the observations and testing data set used 30% of the observations. The set.seed  function was used to make sure that dependent variable was balanced in both datasets.  
```{r, warning=FALSE, message=FALSE}
#Split the data into training dataset and testing dataset with a 70/30 ratio.
set.seed(40)
split = sample.split(v_mod, SplitRatio = 0.70)
v_mod_train = subset(v_mod, split == TRUE) 
v_mod_test = subset(v_mod, split == FALSE)
```

Check the rows for training and testing the datasets
```{r, warning=FALSE, message=FALSE}
#Check the rows for training and testing the datasets
nrow(v_mod_train)
nrow(v_mod_test)
```

We can see that, there are number of observations in the training dataset and observations in the testing dataset are consistent with 70/30 ratio.  

We used forward selection approach in building the linear regression model, which starts with no predictors in the model, iteratively adds the most contributive predictors, and stops when the improvement is no longer statistically significant.  


#### Build a linear model.

**Model 1 - **

### Model1 starts with fewer independent variables.
```{r, warning=FALSE}
# Model1 starts with fewer independent variables.
reg1 <- lm(v_mod_train$tcEquv_Act~v_mod_train$vsl_type + v_mod_train$TotalVoyageDays_Estimate_LatestDaySnapshot)

#Linear Regression Diagnostics
summary(reg1) 

plot(reg1)
```

**Model 2 - **

```{r, warning=FALSE}
# Model 2 adding more independent variables.
reg2 <- lm(v_mod_train$tcEquv_Act~v_mod_train$vsl_type + v_mod_train$TotalVoyageDays_Estimate_LatestDaySnapshot +  v_mod_train$Cargo + v_mod_train$Cargo_Lift_Act)

#Linear Regression Diagnostics
summary(reg2) 

plot(reg2)
```

**Model 3 - **

```{r, warning=FALSE}
# Model 3 adding more independent variables.
reg3 <- lm(v_mod_train$tcEquv_Act~v_mod_train$vsl_type + v_mod_train$TotalVoyageDays_Estimate_LatestDaySnapshot +  v_mod_train$Cargo + v_mod_train$Cargo_Lift_Act + v_mod_train$Month + v_mod_train$lastDiscPort + v_mod_train$dwt)

#Linear Regression Diagnostics
summary(reg3) 

plot(reg3)
```

## **Prediction:**

```{r, warning=FALSE}
# Using model 3 to predict the test dataset.
#result <- predict(reg3)

#summary(result)

#plot(result)

#plot(predict(reg3), v_mod_test$tcEquv_Act)
```

## **Conclusions:**

## **Recommendations:**
1.	Including weather data for each voyage for further analysis will be helpful to get more precise predictions as it is directly related to fuel consumptions.  
2.	To improve the accuracy in the prediction we can try using different algorithms like Random Forest or Extreme gradient boosting.  
3.	Comparison of competitor's business can provide more ideas to improve the business.  
